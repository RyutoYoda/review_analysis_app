import streamlit as st
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from sklearn.neighbors import LocalOutlierFactor
from sklearn.decomposition import PCA
import plotly.express as px
from snownlp import SnowNLP
import re
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# ã‚¢ãƒ—ãƒªã®è¨­å®š
st.set_page_config(page_title="Review Analysis App", page_icon="ğŸ“ˆ")

# ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
st.markdown("""
<style>
body {
    font-family: 'Helvetica Neue', sans-serif;
    background-color: #1e1e1e;
    color: #ffffff;
}
header, footer {
    visibility: hidden;
}
.main {
    background-color: #1e1e1e;
}
.big-font {
    font-size: 36px !important;
    font-weight: bold;
    color: #61dafb;
}
.label-font {
    font-size: 20px !important;
    color: #61dafb;
}
.stButton>button {
    background-color: #61dafb !important;
    color: #ffffff !important;
    border: none !important;
    padding: 10px 20px !important;
    border-radius: 10px !important;
    font-size: 18px !important;
    font-weight: bold !important;
}
.stTextInput>div>div>input {
    background-color: #333333 !important;
    color: #ffffff !important;
    border: 1px solid #61dafb !important;
}
.stSelectbox>div>div>div {
    background-color: #333333 !important;
    color: #ffffff !important;
    border: 1px solid #61dafb !important;
}
.stSlider>div>div>div>div {
    background-color: #61dafb !é‡è¦ã§ã™;
}
</style>
""", unsafe_allow_html=True)

# Streamlitã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«
st.markdown('<div class="big-font">Review Analysis AppğŸ“ˆ</div>', unsafe_allow_html=True)

# ãƒˆã‚°ãƒ«ã§èª¬æ˜ã¨ä½¿ã„æ–¹ã‚’è¡¨ç¤º
with st.expander("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èª¬æ˜ã¨ä½¿ã„æ–¹"):
    st.markdown("""
    ### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èª¬æ˜
    ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€å£ã‚³ãƒŸãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨æ„Ÿæƒ…åˆ†æã‚’è¡Œã†ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š
    - å£ã‚³ãƒŸãƒ‡ãƒ¼ã‚¿ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
    - ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆ3æ¬¡å…ƒãƒ—ãƒ­ãƒƒãƒˆã¨2æ¬¡å…ƒãƒ—ãƒ­ãƒƒãƒˆï¼‰
    - æ„Ÿæƒ…åˆ†æ
    - å¤–ã‚Œå€¤æ¤œå‡ºã¨å¯è¦–åŒ–
    - ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã®ç”Ÿæˆ

    ### ä½¿ã„æ–¹
    1. å£ã‚³ãƒŸãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹CSVã¾ãŸã¯Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    2. å£ã‚³ãƒŸãŒå«ã¾ã‚Œã¦ã„ã‚‹åˆ—ã‚’é¸æŠã—ã¾ã™ã€‚
    3. ã€ŒåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚
    4. ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’é¸æŠã—ã¾ã™ã€‚
    5. ã€Œã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨3æ¬¡å…ƒãƒ—ãƒ­ãƒƒãƒˆã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚
    6. ã€Œæ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚
    7. ã€Œå¤–ã‚Œå€¤æ¤œå‡ºã¨2æ¬¡å…ƒå¯è¦–åŒ–ã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚
    8. ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”Ÿæˆã—ã€é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¦–è¦šçš„ã«ç¢ºèªã§ãã¾ã™ã€‚
    9. å¿…è¦ã«å¿œã˜ã¦ã€ã€Œãƒ‡ãƒ¼ã‚¿ã‚’CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    """)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–
if 'embeddings' not in st.session_state:
    st.session_state.embeddings = None

if 'df' not in st.session_state:
    st.session_state.df = None

if 'num_clusters' not in st.session_state:
    st.session_state.num_clusters = 5

if 'fig' not in st.session_state:
    st.session_state.fig = None

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv", "xlsx"])

if uploaded_file:
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦èª­ã¿è¾¼ã‚€
    if uploaded_file.name.endswith('.csv'):
        df = pd.read_csv(uploaded_file)
    else:
        df = pd.read_excel(uploaded_file)

    st.write("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š", df.head())

    # å£ã‚³ãƒŸãŒå«ã¾ã‚Œã¦ã„ã‚‹åˆ—ã‚’é¸æŠ
    review_column = st.selectbox("å£ã‚³ãƒŸãŒå«ã¾ã‚Œã¦ã„ã‚‹åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„", df.columns)

    # ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ—ä»¥å¤–ã‚’åˆ‡ã‚Šè½ã¨ã—ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼IDã‚’è¿½åŠ 
    st.session_state.df = df[[review_column]].dropna()
    st.session_state.df['review_id'] = st.session_state.df.index

    # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
    def preprocess_text(text):
        text = text.lower()  # å°æ–‡å­—ã«å¤‰æ›
        text = re.sub(r'\d+', '', text)  # æ•°å­—ã‚’å‰Šé™¤
        text = re.sub(r'\s+', ' ', text)  # ä¸è¦ãªç©ºç™½ã‚’å‰Šé™¤
        text = re.sub(r'[^\w\sã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]', '', text)  # ç‰¹æ®Šæ–‡å­—ã‚’å‰Šé™¤ã€æ¼¢å­—ã€ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã‚’å«ã‚€
        return text

    st.session_state.df[review_column] = st.session_state.df[review_column].apply(preprocess_text)

    # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆãƒœã‚¿ãƒ³
    if st.button('åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ'):
        try:
            with st.spinner('åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­...'):
                model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
                st.session_state.embeddings = model.encode(st.session_state.df[review_column].astype(str).tolist())
            st.success('åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼')
            st.progress(100)  # é€²æ—ãƒãƒ¼
        except Exception as e:
            st.error("åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.error(str(e))

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ•°ã®é¸æŠ
    st.session_state.num_clusters = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„", 2, 10, 5)

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨3æ¬¡å…ƒãƒ—ãƒ­ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.session_state.embeddings is not None:
        if st.button('ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨3æ¬¡å…ƒãƒ—ãƒ­ãƒƒãƒˆã‚’å®Ÿè¡Œ'):
            try:
                kmeans = KMeans(n_clusters=st.session_state.num_clusters, random_state=42)
                st.session_state.df['cluster'] = kmeans.fit_predict(st.session_state.embeddings)

                pca = PCA(n_components=3)
                pca_result = pca.fit_transform(st.session_state.embeddings)
                st.session_state.df['pca_one'] = pca_result[:, 0]
                st.session_state.df['pca_two'] = pca_result[:, 1]
                st.session_state.df['pca_three'] = pca_result[:, 2]

                color_sequence = px.colors.qualitative.T10
                st.session_state.fig = px.scatter_3d(
                    st.session_state.df, x='pca_one', y='pca_two', z='pca_three',
                    color='cluster', hover_data=[review_column],
                    color_discrete_sequence=color_sequence[:st.session_state.num_clusters]
                )
                st.plotly_chart(st.session_state.fig, use_container_width=True)

            except Exception as e:
                st.error("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ—ãƒ­ãƒƒãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.error(str(e))

    # æ„Ÿæƒ…åˆ†æãƒœã‚¿ãƒ³
    if st.session_state.embeddings is not None:
        if st.button('æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œ'):
            try:
                def enhanced_sentiment_analysis(text):
                    negative_words = ["æœ€æ‚ª", "ã²ã©ã„", "ä¸æº€", "å¤±æ•—", "å•é¡Œ", "æ‚ªã„"]
                    positive_words = ["æœ€é«˜", "ç´ æ™´ã‚‰ã—ã„", "æº€è¶³", "æˆåŠŸ", "è‰¯ã„"]
                    score = 0
                    for word in negative_words:
                        if word in text:
                            score -= 1
                    for word in positive_words:
                        if word in text:
                            score += 1
                    snow_score = SnowNLP(text).sentiments
                    combined_score = (snow_score * 2) - 1 + (score / max(len(negative_words), len(positive_words)))
                    return 'positive' if combined_score > 0 else 'negative', combined_score

                st.session_state.df['sentiment'], st.session_state.df['sentiment_score'] = zip(*st.session_state.df[review_column].astype(str).apply(enhanced_sentiment_analysis))
                st.write("Sentiment Analysisçµæœï¼š")
                st.write(st.session_state.df[[review_column, 'sentiment', 'sentiment_score']])

            except Exception as e:
                st.error("æ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                st.error(str(e))

    # å¤–ã‚Œå€¤æ¤œå‡ºã¨2æ¬¡å…ƒå¯è¦–åŒ–ãƒœã‚¿ãƒ³
    if st.session_state.embeddings is not None:
        if st.button('å¤–ã‚Œå€¤æ¤œå‡ºã¨2æ¬¡å…ƒå¯è¦–åŒ–ã‚’å®Ÿè¡Œ'):
            try:
                kmeans = KMeans(n_clusters=st.session_state.num_clusters, random_state=42)
                labels = kmeans.fit_predict(st.session_state.embeddings)

                lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)
                outliers = lof.fit_predict(st.session_state.embeddings)
                outlier_scores = lof.negative_outlier_factor_

                pca = PCA(n_components=2)
                reduced_embeddings = pca.fit_transform(st.session_state.embeddings)

                marker_size = np.clip(np.abs(outlier_scores) * 5, 5, 20)
                hover_text = st.session_state.df[review_column].tolist()

                fig = px.scatter(
                    x=reduced_embeddings[:, 0], y=reduced_embeddings[:, 1],
                    color=labels.astype(str), size=marker_size,
                    title="ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã¨å¤–ã‚Œå€¤ã®å¯è¦–åŒ–",
                    labels={'color': 'Cluster'},
                    hover_name=hover_text
                )

                outlier_points = reduced_embeddings[outliers == -1]
                fig.add_scatter(x=outlier_points[:, 0], y=outlier_points[:, 1], mode='markers', marker=dict(color='red', size=10), name='Outliers')
                st.plotly_chart(fig, use_container_width=True)

                # å¤–ã‚Œå€¤ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¿å­˜
                outliers_indices = np.where(outliers == -1)[0]
                outliers_keywords = [st.session_state.df[review_column].iloc[i] for i in outliers_indices]
                outliers_df = pd.DataFrame(outliers_keywords, columns=['Outlier Keywords'])
                st.write("å¤–ã‚Œå€¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼š", outliers_df)

                csv_outliers = outliers_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="å¤–ã‚Œå€¤ãƒ‡ãƒ¼ã‚¿ã‚’CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_outliers,
                    file_name='outliers_keywords.csv',
                    mime='text/csv'
                )

            except Exception as e:
                st.error("å¤–ã‚Œå€¤æ¤œå‡ºã¨å¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                st.error(str(e))

    # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ
    if st.session_state.df is not None:
        if st.button("ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”Ÿæˆ"):
            try:
                all_reviews = ' '.join(st.session_state.df[review_column])
                wordcloud = WordCloud(width=800, height=400, background_color='black', colormap='Blues').generate(all_reviews)

                fig, ax = plt.subplots()
                ax.imshow(wordcloud, interpolation='bilinear')
                ax.axis("off")
                st.pyplot(fig)

            except Exception as e:
                st.error("ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                st.error(str(e))

# ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯
if st.session_state.embeddings is not None and st.session_state.df is not None:
    try:
        def convert_df_to_csv(df):
            return df.to_csv(index=False).encode('utf-8')

        csv = convert_df_to_csv(st.session_state.df)
        st.download_button(
            label="ãƒ‡ãƒ¼ã‚¿ã‚’CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name='review_analysis_result.csv',
            mime='text/csv',
        )

    except Exception as e:
        st.error("ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        st.error(str(e))
